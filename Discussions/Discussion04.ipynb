{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862f3957",
   "metadata": {},
   "source": [
    "# Discussion Week 5\n",
    "\n",
    "In this discussion we review eigenvalues and the SVD. \n",
    "\n",
    "You can use the Shared Computing Cluster (SCC) or Google Colab to run this notebook.\n",
    "\n",
    "The general instructions for running on the SCC are available under General Resources on [Piazza](https://piazza.com/bu/fall2025/ds722/resources)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52941e76",
   "metadata": {},
   "source": [
    "# Problem: Computing Eigenvalues and Eigenvectors\n",
    "\n",
    "Compute by hand the eigenvalues and eigenvectors of the matrix:\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "0 & -1 \\\\\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Verify your calculations numerically using the `numpy.linalg.eig`. function. The documentation for this function can be found [here](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html).\n",
    "\n",
    "Recall the step-by-step instructions for computing the eigenvalues of a $2\\times 2$ matrix\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "### Step 1: Compute the Characteristic Polynomial\n",
    "\n",
    "Find eigenvalues $\\lambda $ by solving the characteristic equation:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) = 0.\n",
    "$$\n",
    "\n",
    "This becomes:\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "a - \\lambda & b \\\\\n",
    "c & d - \\lambda\n",
    "\\end{vmatrix}\n",
    "= (a - \\lambda)(d - \\lambda) - bc = 0.\n",
    "$$\n",
    "\n",
    "Simplify to get a quadratic equation:\n",
    "\n",
    "$$\n",
    "\\lambda^2 - (a + d)\\lambda + (ad - bc) = 0.\n",
    "$$\n",
    "\n",
    "### Step 2: Solve for Eigenvalues\n",
    "\n",
    "Solve the quadratic equation for $\\lambda$:\n",
    "\n",
    "$$\n",
    "\\lambda = \\frac{(a + d) \\pm \\sqrt{(a + d)^2 - 4(ad - bc)}}{2}.\n",
    "$$\n",
    "\n",
    "These values are your **eigenvalues**.\n",
    "\n",
    "\n",
    "### Step 3: Find Eigenvectors\n",
    "\n",
    "For each eigenvalue $\\lambda$, solve:\n",
    "\n",
    "$$\n",
    "(A - \\lambda I)v= 0.\n",
    "$$\n",
    "\n",
    "This produces a system of linear equations. Solve to find the non-zero vector $v$ that satisfies the equation â€” the corresponding eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fe110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44ada5",
   "metadata": {},
   "source": [
    "## Problem: PCA vs SVD on the Iris Dataset\n",
    "\n",
    "In this exercise, you'll perform Principal Component Analysis (PCA) on the classic Iris dataset and compare the results with standard SVD.\n",
    "\n",
    "### Step 1: Load and Preprocess the Data\n",
    "\n",
    "- Load the Iris dataset using `sklearn.datasets.load_iris`.\n",
    "- Extract the feature matrix $A \\in \\mathbb{R}^{150 \\times 4}$.\n",
    "- Center the data by subtracting the mean of each feature.\n",
    "\n",
    "### Step 2: Perform PCA\n",
    "\n",
    "PCA is theoretically explained by computing the eigenvalues and eigenvectors of the covariance matrix of the data. The eigenvectors correspond to the principal components, and the eigenvalues indicate the amount of variance captured by each principal component.\n",
    "\n",
    "- Perform PCA using `sklearn.decomposition.PCA` from scikit-learn with `n_components=2`. The documentation for PCA can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "- The PCA scores are the coordinates of your data in the feature space. Print the first 10 PCA scores. \n",
    "- Print the explained variance using the `explained_variance_` attribute of the PCA object.\n",
    "\n",
    "### Step 3: Perform SVD\n",
    "\n",
    "- Apply `numpy.linalg.svd` directly to the centered data matrix $A$.\n",
    "- Use the first two columns of $V$ (right singular vectors) to project the data, i.e., compute the projection as $AV_{[:, :2]}$. Print the first 10 entries of the projected data. Compare the SVD-based projection with the PCA-based projection.\n",
    "- Compute the explained variance from the singular values. This is done by computing $\\sigma_{i}^{2}$ and dividing by (n-1), where n is the number of features. The output should be an array of length 4. Print the first two entries of the explained variance using the singular values returned by the SVD.\n",
    "\n",
    "### Step 4: Visualization\n",
    "\n",
    "- Plot the PCA and SVD projections side by side.\n",
    "- Color the points by their species labels.\n",
    "- Be aware that the figures may differ by a rotation or reflection, which is expected since PCA and SVD can yield results that are equivalent up to such transformations.\n",
    "\n",
    "\n",
    "### Test your Understanding\n",
    "\n",
    "1. Do the PCA scores and the SVD projections look similar?\n",
    "1. What is the relationship between the PCA scores and the factors $A$ and $V$ in the SVD?\n",
    "1. What do the singular values represent in the context of PCA?\n",
    "1. How are the eigenvalues and eigenvectors of the covariance matrix related to the SVD of the centered data matrix?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3abfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO SVD Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de124549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds722",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
